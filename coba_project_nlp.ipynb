{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Stemming Tweet Classification**\n",
        "\n",
        "1.   Stanley Pudjowibowo 20.K1.0006\n",
        "2.   Daniel Hartanto 20.K1.0008\n",
        "3.   Jonathan Kevin Giustino 20.K1.0009\n",
        "\n"
      ],
      "metadata": {
        "id": "vBAULqF-PN-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rizalespe/Dataset-Sentimen-Analisis-Bahasa-Indonesia.git\n",
        "!pip install PySastrawi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8hbRDIPCBd3",
        "outputId": "21cddc83-2e58-4346-c7d6-fb3eb82af3d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Dataset-Sentimen-Analisis-Bahasa-Indonesia'...\n",
            "remote: Enumerating objects: 169, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 169 (delta 24), reused 0 (delta 0), pack-reused 123\u001b[K\n",
            "Receiving objects: 100% (169/169), 164.89 KiB | 3.30 MiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n",
            "Collecting PySastrawi\n",
            "  Downloading PySastrawi-1.2.0-py2.py3-none-any.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m210.6/210.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PySastrawi\n",
            "Successfully installed PySastrawi-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "np.random.seed(0)\n",
        "# membuat stemmer\n",
        "factory = StemmerFactory()\n",
        "stemmer_sastrawi = factory.create_stemmer()\n",
        "# nltk.download('stopwords')\n",
        "# nltk.download('averaged_perceptron_tagger')\n",
        "# nltk.download('maxent_ne_chunker')\n",
        "# nltk.download('words')\n",
        "# stopwords_list = stopwords.words('english')\n",
        "\n",
        "# tokenizer\n",
        "tk = TweetTokenizer()\n",
        "\n",
        "np.random.seed(0)\n",
        "# read data csv\n",
        "corpus = pd.read_csv('/content/Dataset-Sentimen-Analisis-Bahasa-Indonesia/dataset_tweet_sentiment_pilkada_DKI_2017.csv')\n",
        "# read stopword csv\n",
        "stopword_list = pd.read_csv('/content/Dataset-Sentimen-Analisis-Bahasa-Indonesia/stopword_tweet_pilkada_DKI_2017.csv')\n",
        "# read emoji csv\n",
        "emojis = pd.read_csv('/content/Dataset-Sentimen-Analisis-Bahasa-Indonesia/master_emoji.csv')"
      ],
      "metadata": {
        "id": "85_bxyoYZRwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# changing <Angry Face> into <Angry_Face>\n",
        "def space(text):\n",
        "  return re.sub(\"\\s\", \"_\", text)\n",
        "emojis['emot']=emojis['Special Tag'].apply(lambda x: space(x))\n",
        "emojis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "G_ZvUi0jhmPr",
        "outputId": "02aa2cf9-4e19-432f-e8d3-cb6cb602b776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      ID       Emoji Sentiment  \\\n",
              "0      1           üòõ  negative   \n",
              "1      2           üò†  negative   \n",
              "2      3           üí£  negative   \n",
              "3      4           üíî  negative   \n",
              "4      5           üòï  negative   \n",
              "..   ...         ...       ...   \n",
              "160  161           üí°  positive   \n",
              "161  162           üìà  positive   \n",
              "162  163           üíØ  positive   \n",
              "163  164           üÜó  positive   \n",
              "164  165  üë®üèΩ‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë©üèº  positive   \n",
              "\n",
              "                                           Makna Emoji  \\\n",
              "0                           Face With Stuck-Out Tongue   \n",
              "1                                           Angry Face   \n",
              "2                                                 Bomb   \n",
              "3                                         Broken Heart   \n",
              "4                                        Confused Face   \n",
              "..                                                 ...   \n",
              "160                                         Light Bulb   \n",
              "161                                   Chart Increasing   \n",
              "162                                     Hundred Points   \n",
              "163                                          OK Button   \n",
              "164  Kiss - Man Medium Skin Tone Woman MediumLight ...   \n",
              "\n",
              "                                           Special Tag  \\\n",
              "0                        <FACE WITH STUCK-OUT TOUNGES>   \n",
              "1                                         <Angry Face>   \n",
              "2                                               <Bomb>   \n",
              "3                                       <Broken Heart>   \n",
              "4                                      <Confused Face>   \n",
              "..                                                 ...   \n",
              "160                                       <Light Bulb>   \n",
              "161                                 <Chart Increasing>   \n",
              "162                                   <Hundred Points>   \n",
              "163                                        <OK Button>   \n",
              "164  <Kiss - Man Medium Skin Tone Woman MediumLight...   \n",
              "\n",
              "                                                  emot  \n",
              "0                       _<FACE_WITH_STUCK-OUT_TOUNGES>  \n",
              "1                                         <Angry_Face>  \n",
              "2                                               <Bomb>  \n",
              "3                                       <Broken_Heart>  \n",
              "4                                      <Confused_Face>  \n",
              "..                                                 ...  \n",
              "160                                       <Light_Bulb>  \n",
              "161                                 <Chart_Increasing>  \n",
              "162                                   <Hundred_Points>  \n",
              "163                                        <OK_Button>  \n",
              "164  <Kiss_-_Man_Medium_Skin_Tone_Woman_MediumLight...  \n",
              "\n",
              "[165 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b060d4a6-1c84-479e-9d89-b3b30a8e5509\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Emoji</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Makna Emoji</th>\n",
              "      <th>Special Tag</th>\n",
              "      <th>emot</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>üòõ</td>\n",
              "      <td>negative</td>\n",
              "      <td>Face With Stuck-Out Tongue</td>\n",
              "      <td>&lt;FACE WITH STUCK-OUT TOUNGES&gt;</td>\n",
              "      <td>_&lt;FACE_WITH_STUCK-OUT_TOUNGES&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>üò†</td>\n",
              "      <td>negative</td>\n",
              "      <td>Angry Face</td>\n",
              "      <td>&lt;Angry Face&gt;</td>\n",
              "      <td>&lt;Angry_Face&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>üí£</td>\n",
              "      <td>negative</td>\n",
              "      <td>Bomb</td>\n",
              "      <td>&lt;Bomb&gt;</td>\n",
              "      <td>&lt;Bomb&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>üíî</td>\n",
              "      <td>negative</td>\n",
              "      <td>Broken Heart</td>\n",
              "      <td>&lt;Broken Heart&gt;</td>\n",
              "      <td>&lt;Broken_Heart&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>üòï</td>\n",
              "      <td>negative</td>\n",
              "      <td>Confused Face</td>\n",
              "      <td>&lt;Confused Face&gt;</td>\n",
              "      <td>&lt;Confused_Face&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>161</td>\n",
              "      <td>üí°</td>\n",
              "      <td>positive</td>\n",
              "      <td>Light Bulb</td>\n",
              "      <td>&lt;Light Bulb&gt;</td>\n",
              "      <td>&lt;Light_Bulb&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>162</td>\n",
              "      <td>üìà</td>\n",
              "      <td>positive</td>\n",
              "      <td>Chart Increasing</td>\n",
              "      <td>&lt;Chart Increasing&gt;</td>\n",
              "      <td>&lt;Chart_Increasing&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>163</td>\n",
              "      <td>üíØ</td>\n",
              "      <td>positive</td>\n",
              "      <td>Hundred Points</td>\n",
              "      <td>&lt;Hundred Points&gt;</td>\n",
              "      <td>&lt;Hundred_Points&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>164</td>\n",
              "      <td>üÜó</td>\n",
              "      <td>positive</td>\n",
              "      <td>OK Button</td>\n",
              "      <td>&lt;OK Button&gt;</td>\n",
              "      <td>&lt;OK_Button&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>165</td>\n",
              "      <td>üë®üèΩ‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë©üèº</td>\n",
              "      <td>positive</td>\n",
              "      <td>Kiss - Man Medium Skin Tone Woman MediumLight ...</td>\n",
              "      <td>&lt;Kiss - Man Medium Skin Tone Woman MediumLight...</td>\n",
              "      <td>&lt;Kiss_-_Man_Medium_Skin_Tone_Woman_MediumLight...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>165 rows √ó 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b060d4a6-1c84-479e-9d89-b3b30a8e5509')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b060d4a6-1c84-479e-9d89-b3b30a8e5509 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b060d4a6-1c84-479e-9d89-b3b30a8e5509');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "N6RTq3mtDK-A",
        "outputId": "9c7188ff-e7ad-4ecd-d52e-5d08335944b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Id Sentiment Pasangan Calon  \\\n",
              "0      1  negative     Agus-Sylvi   \n",
              "1      2  negative     Agus-Sylvi   \n",
              "2      3  negative     Agus-Sylvi   \n",
              "3      4  negative     Agus-Sylvi   \n",
              "4      5  negative     Agus-Sylvi   \n",
              "..   ...       ...            ...   \n",
              "895  896  positive    Anies-Sandi   \n",
              "896  897  positive    Anies-Sandi   \n",
              "897  898  positive    Anies-Sandi   \n",
              "898  899  positive    Anies-Sandi   \n",
              "899  900  positive    Anies-Sandi   \n",
              "\n",
              "                                            Text Tweet  \n",
              "0    Banyak akun kloning seolah2 pendukung #agussil...  \n",
              "1    #agussilvy bicara apa kasihan yaa...lap itu ai...  \n",
              "2    Kalau aku sih gak nunggu hasil akhir QC tp lag...  \n",
              "3    Kasian oh kasian dengan peluru 1milyar untuk t...  \n",
              "4    Maaf ya pendukung #AgusSilvy..hayo dukung #Ani...  \n",
              "..                                                 ...  \n",
              "895  Kali saja bpk @aniesbaswedan @sandiuno lihat, ...  \n",
              "896  Kita harus dapat merangkul semua orang tanpa b...  \n",
              "897  Ini jagoanku dibidang digital <Smiling Face Wi...  \n",
              "898               #PesanBijak #OkeOce #GubernurGu3 ...  \n",
              "899  Sandiaga: Bangun Rumah DP 0% Lebih Simpel Diba...  \n",
              "\n",
              "[900 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2670a602-7c3c-4d92-ad3d-009f6c9deab5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Pasangan Calon</th>\n",
              "      <th>Text Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>negative</td>\n",
              "      <td>Agus-Sylvi</td>\n",
              "      <td>Banyak akun kloning seolah2 pendukung #agussil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>negative</td>\n",
              "      <td>Agus-Sylvi</td>\n",
              "      <td>#agussilvy bicara apa kasihan yaa...lap itu ai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>negative</td>\n",
              "      <td>Agus-Sylvi</td>\n",
              "      <td>Kalau aku sih gak nunggu hasil akhir QC tp lag...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>negative</td>\n",
              "      <td>Agus-Sylvi</td>\n",
              "      <td>Kasian oh kasian dengan peluru 1milyar untuk t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>negative</td>\n",
              "      <td>Agus-Sylvi</td>\n",
              "      <td>Maaf ya pendukung #AgusSilvy..hayo dukung #Ani...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>895</th>\n",
              "      <td>896</td>\n",
              "      <td>positive</td>\n",
              "      <td>Anies-Sandi</td>\n",
              "      <td>Kali saja bpk @aniesbaswedan @sandiuno lihat, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>896</th>\n",
              "      <td>897</td>\n",
              "      <td>positive</td>\n",
              "      <td>Anies-Sandi</td>\n",
              "      <td>Kita harus dapat merangkul semua orang tanpa b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897</th>\n",
              "      <td>898</td>\n",
              "      <td>positive</td>\n",
              "      <td>Anies-Sandi</td>\n",
              "      <td>Ini jagoanku dibidang digital &lt;Smiling Face Wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>898</th>\n",
              "      <td>899</td>\n",
              "      <td>positive</td>\n",
              "      <td>Anies-Sandi</td>\n",
              "      <td>#PesanBijak #OkeOce #GubernurGu3 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>899</th>\n",
              "      <td>900</td>\n",
              "      <td>positive</td>\n",
              "      <td>Anies-Sandi</td>\n",
              "      <td>Sandiaga: Bangun Rumah DP 0% Lebih Simpel Diba...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>900 rows √ó 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2670a602-7c3c-4d92-ad3d-009f6c9deab5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2670a602-7c3c-4d92-ad3d-009f6c9deab5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2670a602-7c3c-4d92-ad3d-009f6c9deab5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#change sentiment into index\n",
        "idx2category = corpus['Sentiment'].unique()\n",
        "category2idx = dict(zip(idx2category, np.arange(len(idx2category))))\n",
        "\n",
        "print(\"idx2category\", idx2category)\n",
        "print(\"category2idx\", category2idx)\n",
        "corpus['Sentiment'] = corpus['Sentiment'].apply(lambda x : category2idx[x])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVweYJMooCZ0",
        "outputId": "2c4d694a-5946-4220-d822-681d1d42184e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idx2category ['negative' 'positive']\n",
            "category2idx {'negative': 0, 'positive': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(corpus, test_size=0.3)\n",
        "train"
      ],
      "metadata": {
        "id": "ieHcM3TwZsTI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "5f22543a-2240-4848-dc87-ad369fbf8984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Id  Sentiment Pasangan Calon  \\\n",
              "76    77          0     Agus-Sylvi   \n",
              "48    49          0     Agus-Sylvi   \n",
              "664  665          0    Anies-Sandi   \n",
              "263  264          1     Agus-Sylvi   \n",
              "727  728          0    Anies-Sandi   \n",
              "..   ...        ...            ...   \n",
              "835  836          1    Anies-Sandi   \n",
              "192  193          1     Agus-Sylvi   \n",
              "629  630          0    Anies-Sandi   \n",
              "559  560          1    Ahok-Djarot   \n",
              "684  685          0    Anies-Sandi   \n",
              "\n",
              "                                            Text Tweet  \n",
              "76   Sah-sah aja, Justru itu menjadi tolak ukur ked...  \n",
              "48   Masih mau mencaci maki #AHY dan Pepo Memo nya?...  \n",
              "664  DP 0 persen ternyata beda dengan DP 0 rupiah, ...  \n",
              "263                   #AHY dukung #HariSantriNasional   \n",
              "727  Hati2 terprovokasi ya teman. Ini bukan wajah i...  \n",
              "..                                                 ...  \n",
              "835  Siiiip pak. Selalu bantu dan kawal #AniesSandi...  \n",
              "192  Salut! @AgusYudhoyono & Mpok Silvy dengan meng...  \n",
              "629  Lho, Lagu Anies-Sandi Menjiplak Nyanyian Yahud...  \n",
              "559  Ayo coblos yang bijaksana untuk JAKARTA yang l...  \n",
              "684  Ente Kafirun nantangin laskar #AniesSandi ??! ...  \n",
              "\n",
              "[630 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb7b8635-0db4-4176-8ebe-cb0aa59f18bd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Pasangan Calon</th>\n",
              "      <th>Text Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>77</td>\n",
              "      <td>0</td>\n",
              "      <td>Agus-Sylvi</td>\n",
              "      <td>Sah-sah aja, Justru itu menjadi tolak ukur ked...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>Agus-Sylvi</td>\n",
              "      <td>Masih mau mencaci maki #AHY dan Pepo Memo nya?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>664</th>\n",
              "      <td>665</td>\n",
              "      <td>0</td>\n",
              "      <td>Anies-Sandi</td>\n",
              "      <td>DP 0 persen ternyata beda dengan DP 0 rupiah, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>264</td>\n",
              "      <td>1</td>\n",
              "      <td>Agus-Sylvi</td>\n",
              "      <td>#AHY dukung #HariSantriNasional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>727</th>\n",
              "      <td>728</td>\n",
              "      <td>0</td>\n",
              "      <td>Anies-Sandi</td>\n",
              "      <td>Hati2 terprovokasi ya teman. Ini bukan wajah i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>835</th>\n",
              "      <td>836</td>\n",
              "      <td>1</td>\n",
              "      <td>Anies-Sandi</td>\n",
              "      <td>Siiiip pak. Selalu bantu dan kawal #AniesSandi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>193</td>\n",
              "      <td>1</td>\n",
              "      <td>Agus-Sylvi</td>\n",
              "      <td>Salut! @AgusYudhoyono &amp; Mpok Silvy dengan meng...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>629</th>\n",
              "      <td>630</td>\n",
              "      <td>0</td>\n",
              "      <td>Anies-Sandi</td>\n",
              "      <td>Lho, Lagu Anies-Sandi Menjiplak Nyanyian Yahud...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559</th>\n",
              "      <td>560</td>\n",
              "      <td>1</td>\n",
              "      <td>Ahok-Djarot</td>\n",
              "      <td>Ayo coblos yang bijaksana untuk JAKARTA yang l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>684</th>\n",
              "      <td>685</td>\n",
              "      <td>0</td>\n",
              "      <td>Anies-Sandi</td>\n",
              "      <td>Ente Kafirun nantangin laskar #AniesSandi ??! ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>630 rows √ó 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb7b8635-0db4-4176-8ebe-cb0aa59f18bd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cb7b8635-0db4-4176-8ebe-cb0aa59f18bd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cb7b8635-0db4-4176-8ebe-cb0aa59f18bd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing with stemmers\n",
        "def preprocessing_sastrawi(text):\n",
        "    token = None\n",
        "    # removing url\n",
        "    text= re.sub(r'http\\S+', '', text)\n",
        "    # removing special character ( username and hashtag)\n",
        "    text = re.sub(r\"@\\w+\", '@username', text) # mengganti username\n",
        "    text = re.sub(r\"#\\w+\", '#hastag', text) # mengganti hastag\n",
        "    # changing emoticon\n",
        "    for i in range(len(emojis)):\n",
        "      text = re.sub(emojis['Special Tag'][i], emojis['emot'][i], text)\n",
        "    # Punctuation removal (rmoving symbols)\n",
        "    text=re.sub(r\"[^a-zA-Z0-9\\s<>]\", \"\", text)\n",
        "    # Case folding\n",
        "    text=text.lower()\n",
        "    # Tokenizer\n",
        "    token_text= tk.tokenize(text)\n",
        "    # Stopword Removal and Stemming\n",
        "    token = [stemmer_sastrawi.stem(word) for word in token_text if word not in stopword_list]\n",
        "    return \" \".join(token)\n",
        "# Preprocessing without stemmers\n",
        "def preprocessing_without_stemmer(text):\n",
        "    token = None\n",
        "    # removing url\n",
        "    text= re.sub(r'http\\S+', '', text)\n",
        "    # removing special character ( username and hashtag)\n",
        "    text = re.sub(r\"@\\w+\", '@username', text) # mengganti username\n",
        "    text = re.sub(r\"#\\w+\", '@username', text) # mengganti hastag\n",
        "    # changing emoticon\n",
        "    for i in range(len(emojis)):\n",
        "      text = re.sub(emojis['Special Tag'][i], emojis['emot'][i], text)\n",
        "    # Punctuation removal (rmoving symbols)\n",
        "    text=re.sub(r\"[^a-zA-Z0-9\\s<>]\", \"\", text)\n",
        "    # Case folding\n",
        "    text=text.lower()\n",
        "    # Tokenizer\n",
        "    token_text= tk.tokenize(text)\n",
        "    # Stopword Removal\n",
        "    token = [word for word in token_text if word not in stopword_list]\n",
        "    return \" \".join(token)"
      ],
      "metadata": {
        "id": "li6iSFIGYLjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TF-IDF with stemmer"
      ],
      "metadata": {
        "id": "gR9Xf23H7Cqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "# With stemmer\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,1), preprocessor=preprocessing_sastrawi)\n",
        "print(\"-------with stemmer-----\")\n",
        "# Without stemmers\n",
        "#vectorizer = TfidfVectorizer(ngram_range=(1,1), preprocessor=preprocessing_without_stemmer)\n",
        "#print(\"-------without stemmer-----\")\n",
        "\n",
        "# Preprocess and turn into vector\n",
        "X_train = vectorizer.fit_transform(train['Text Tweet'].values.tolist())\n",
        "\n",
        "\n",
        "# using multinomial naive bayes\n",
        "print(\"-------Multinomial Naive Bayes-----\")\n",
        "clf = MultinomialNB(alpha=0.01)\n",
        "X = X_train\n",
        "y = train['Sentiment'].values\n",
        "\n",
        "clf.fit(X, y)\n",
        "pred = clf.predict(X)\n",
        "print(\"------train--------\")\n",
        "print(classification_report(y, pred))\n",
        "\n",
        "X_test = vectorizer.transform(test['Text Tweet'].values.tolist())\n",
        "y_test = test['Sentiment'].values\n",
        "\n",
        "pred = clf.predict(X_test)\n",
        "print(\"------test--------\")\n",
        "print(classification_report(y_test, pred))\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, pred)\n",
        "\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "\n",
        "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
        "\n",
        "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
        "\n",
        "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
        "\n",
        "print('\\nFalse Negatives(FN) = ', cm[1,0])\n",
        "\n",
        "print(\"------test (in long)--------\")\n",
        "precision, recall, fscore, support = precision_recall_fscore_support(y_test, pred, average='macro')\n",
        "print(\"Precision =\", precision)\n",
        "print(\"recall =\", recall)\n",
        "print(\"fscore =\", fscore)\n",
        "\n",
        "\n",
        "#using svm\n",
        "print(\"----------------SVM----------\")\n",
        "svc = SVC()\n",
        "X = X_train\n",
        "y = train['Sentiment'].values\n",
        "\n",
        "svc.fit(X, y)\n",
        "pred = svc.predict(X)\n",
        "print(\"------train--------\")\n",
        "print(classification_report(y, pred))\n",
        "\n",
        "X_test = vectorizer.transform(test['Text Tweet'].values.tolist())\n",
        "y_test = test['Sentiment'].values\n",
        "\n",
        "pred = svc.predict(X_test)\n",
        "print(\"------test--------\")\n",
        "print(classification_report(y_test, pred))\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, pred)\n",
        "\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "\n",
        "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
        "\n",
        "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
        "\n",
        "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
        "\n",
        "print('\\nFalse Negatives(FN) = ', cm[1,0])\n",
        "\n",
        "print(\"------test (in long)--------\")\n",
        "precision, recall, fscore, support = precision_recall_fscore_support(y_test, pred, average='macro')\n",
        "print(\"Precision =\", precision)\n",
        "print(\"recall =\", recall)\n",
        "print(\"fscore =\", fscore)\n"
      ],
      "metadata": {
        "id": "NQ66kkv7WSbQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f510b755-760b-43a0-d50a-567b962986be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------with stemmer-----\n",
            "-------Multinomial Naive Bayes-----\n",
            "------train--------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       315\n",
            "           1       0.99      1.00      0.99       315\n",
            "\n",
            "    accuracy                           0.99       630\n",
            "   macro avg       0.99      0.99      0.99       630\n",
            "weighted avg       0.99      0.99      0.99       630\n",
            "\n",
            "------test--------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.67      0.69       135\n",
            "           1       0.69      0.73      0.71       135\n",
            "\n",
            "    accuracy                           0.70       270\n",
            "   macro avg       0.70      0.70      0.70       270\n",
            "weighted avg       0.70      0.70      0.70       270\n",
            "\n",
            "Confusion matrix\n",
            "\n",
            " [[91 44]\n",
            " [36 99]]\n",
            "\n",
            "True Positives(TP) =  91\n",
            "\n",
            "True Negatives(TN) =  99\n",
            "\n",
            "False Positives(FP) =  44\n",
            "\n",
            "False Negatives(FN) =  36\n",
            "------test (in long)--------\n",
            "Precision = 0.7044215626892791\n",
            "recall = 0.7037037037037037\n",
            "fscore = 0.7034433521884782\n",
            "----------------SVM----------\n",
            "------train--------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       315\n",
            "           1       1.00      1.00      1.00       315\n",
            "\n",
            "    accuracy                           1.00       630\n",
            "   macro avg       1.00      1.00      1.00       630\n",
            "weighted avg       1.00      1.00      1.00       630\n",
            "\n",
            "------test--------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.73      0.73       135\n",
            "           1       0.73      0.75      0.74       135\n",
            "\n",
            "    accuracy                           0.74       270\n",
            "   macro avg       0.74      0.74      0.74       270\n",
            "weighted avg       0.74      0.74      0.74       270\n",
            "\n",
            "Confusion matrix\n",
            "\n",
            " [[ 98  37]\n",
            " [ 34 101]]\n",
            "\n",
            "True Positives(TP) =  98\n",
            "\n",
            "True Negatives(TN) =  101\n",
            "\n",
            "False Positives(FP) =  37\n",
            "\n",
            "False Negatives(FN) =  34\n",
            "------test (in long)--------\n",
            "Precision = 0.7371541501976284\n",
            "recall = 0.737037037037037\n",
            "fscore = 0.7370045684652426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF without stemmer"
      ],
      "metadata": {
        "id": "AHo-LYNv7LOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "# With stemmer\n",
        "#vectorizer = TfidfVectorizer(ngram_range=(1,1), preprocessor=preprocessing_sastrawi)\n",
        "# print(\"-------with stemmer-----\")\n",
        "\n",
        "# Without stemmers\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,1), preprocessor=preprocessing_without_stemmer)\n",
        "print(\"-------without stemmer-----\")\n",
        "\n",
        "# Preprocess and turn into vector\n",
        "X_train = vectorizer.fit_transform(train['Text Tweet'].values.tolist())\n",
        "\n",
        "# using multinomial naive bayes\n",
        "print(\"-------Multinomial Naive Bayes-----\")\n",
        "clf = MultinomialNB(alpha=0.01)\n",
        "X = X_train\n",
        "y = train['Sentiment'].values\n",
        "\n",
        "clf.fit(X, y)\n",
        "pred = clf.predict(X)\n",
        "print(\"------train--------\")\n",
        "print(classification_report(y, pred))\n",
        "\n",
        "X_test = vectorizer.transform(test['Text Tweet'].values.tolist())\n",
        "y_test = test['Sentiment'].values\n",
        "\n",
        "pred = clf.predict(X_test)\n",
        "print(\"------test--------\")\n",
        "print(classification_report(y_test, pred))\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, pred)\n",
        "\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "\n",
        "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
        "\n",
        "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
        "\n",
        "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
        "\n",
        "print('\\nFalse Negatives(FN) = ', cm[1,0])\n",
        "\n",
        "print(\"------test (in long)--------\")\n",
        "precision, recall, fscore, support = precision_recall_fscore_support(y_test, pred, average='macro')\n",
        "print(\"Precision =\", precision)\n",
        "print(\"recall =\", recall)\n",
        "print(\"fscore =\", fscore)\n",
        "\n",
        "\n",
        "#using svm\n",
        "print(\"----------------SVM----------\")\n",
        "svc = SVC()\n",
        "X = X_train\n",
        "y = train['Sentiment'].values\n",
        "\n",
        "svc.fit(X, y)\n",
        "pred = svc.predict(X)\n",
        "print(\"------train--------\")\n",
        "print(classification_report(y, pred))\n",
        "\n",
        "X_test = vectorizer.transform(test['Text Tweet'].values.tolist())\n",
        "y_test = test['Sentiment'].values\n",
        "\n",
        "pred = svc.predict(X_test)\n",
        "print(\"------test--------\")\n",
        "print(classification_report(y_test, pred))\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, pred)\n",
        "\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "\n",
        "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
        "\n",
        "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
        "\n",
        "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
        "\n",
        "print('\\nFalse Negatives(FN) = ', cm[1,0])\n",
        "\n",
        "print(\"------test (in long)--------\")\n",
        "precision, recall, fscore, support = precision_recall_fscore_support(y_test, pred, average='macro')\n",
        "print(\"Precision =\", precision)\n",
        "print(\"recall =\", recall)\n",
        "print(\"fscore =\", fscore)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UggrDylY7R4t",
        "outputId": "8bd1f1ba-c4a3-4814-c502-4e18eae12e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------without stemmer-----\n",
            "-------Multinomial Naive Bayes-----\n",
            "------train--------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00       315\n",
            "           1       0.99      1.00      1.00       315\n",
            "\n",
            "    accuracy                           1.00       630\n",
            "   macro avg       1.00      1.00      1.00       630\n",
            "weighted avg       1.00      1.00      1.00       630\n",
            "\n",
            "------test--------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.67      0.69       135\n",
            "           1       0.69      0.72      0.70       135\n",
            "\n",
            "    accuracy                           0.70       270\n",
            "   macro avg       0.70      0.70      0.70       270\n",
            "weighted avg       0.70      0.70      0.70       270\n",
            "\n",
            "Confusion matrix\n",
            "\n",
            " [[91 44]\n",
            " [38 97]]\n",
            "\n",
            "True Positives(TP) =  91\n",
            "\n",
            "True Negatives(TN) =  97\n",
            "\n",
            "False Positives(FP) =  44\n",
            "\n",
            "False Negatives(FN) =  38\n",
            "------test (in long)--------\n",
            "Precision = 0.6966848095002474\n",
            "recall = 0.6962962962962963\n",
            "fscore = 0.6961462450592886\n",
            "----------------SVM----------\n",
            "------train--------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       315\n",
            "           1       1.00      1.00      1.00       315\n",
            "\n",
            "    accuracy                           1.00       630\n",
            "   macro avg       1.00      1.00      1.00       630\n",
            "weighted avg       1.00      1.00      1.00       630\n",
            "\n",
            "------test--------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.73      0.74       135\n",
            "           1       0.74      0.75      0.74       135\n",
            "\n",
            "    accuracy                           0.74       270\n",
            "   macro avg       0.74      0.74      0.74       270\n",
            "weighted avg       0.74      0.74      0.74       270\n",
            "\n",
            "Confusion matrix\n",
            "\n",
            " [[ 99  36]\n",
            " [ 34 101]]\n",
            "\n",
            "True Positives(TP) =  99\n",
            "\n",
            "True Negatives(TN) =  101\n",
            "\n",
            "False Positives(FP) =  36\n",
            "\n",
            "False Negatives(FN) =  34\n",
            "------test (in long)--------\n",
            "Precision = 0.7407935898139509\n",
            "recall = 0.7407407407407407\n",
            "fscore = 0.7407265144863915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Count Vectorizer with stemmer"
      ],
      "metadata": {
        "id": "5pgJmWjy56Hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# With stemmer\n",
        "vectorizer = CountVectorizer(ngram_range=(1,1), preprocessor=preprocessing_sastrawi)\n",
        "print(\"-------with stemmer-----\")\n",
        "# Without stemmers\n",
        "#vectorizer = CountVectorizer(ngram_range=(1,1), preprocessor=preprocessing_without_stemmer)\n",
        "#print(\"-------without stemmer-----\")\n",
        "\n",
        "# Preprocess and turn into vector\n",
        "X_train = vectorizer.fit_transform(train['Text Tweet'].values.tolist())\n",
        "\n",
        "\n",
        "# using multinomial naive bayes\n",
        "print(\"-------Multinomial Naive Bayes-----\")\n",
        "clf = MultinomialNB(alpha=0.01)\n",
        "X = X_train\n",
        "y = train['Sentiment'].values\n",
        "\n",
        "clf.fit(X, y)\n",
        "pred = clf.predict(X)\n",
        "print(\"------train--------\")\n",
        "print(classification_report(y, pred))\n",
        "\n",
        "X_test = vectorizer.transform(test['Text Tweet'].values.tolist())\n",
        "y_test = test['Sentiment'].values\n",
        "\n",
        "pred = clf.predict(X_test)\n",
        "print(\"------test--------\")\n",
        "print(classification_report(y_test, pred))\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, pred)\n",
        "\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "\n",
        "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
        "\n",
        "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
        "\n",
        "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
        "\n",
        "print('\\nFalse Negatives(FN) = ', cm[1,0])\n",
        "\n",
        "print(\"------test (in long)--------\")\n",
        "precision, recall, fscore, support = precision_recall_fscore_support(y_test, pred, average='macro')\n",
        "print(\"Precision =\", precision)\n",
        "print(\"recall =\", recall)\n",
        "print(\"fscore =\", fscore)\n",
        "\n",
        "\n",
        "#using svm\n",
        "print(\"----------------SVM----------\")\n",
        "svc = SVC()\n",
        "X = X_train\n",
        "y = train['Sentiment'].values\n",
        "\n",
        "svc.fit(X, y)\n",
        "pred = svc.predict(X)\n",
        "print(\"------train--------\")\n",
        "print(classification_report(y, pred))\n",
        "\n",
        "X_test = vectorizer.transform(test['Text Tweet'].values.tolist())\n",
        "y_test = test['Sentiment'].values\n",
        "\n",
        "pred = svc.predict(X_test)\n",
        "print(\"------test--------\")\n",
        "print(classification_report(y_test, pred))\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, pred)\n",
        "\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "\n",
        "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
        "\n",
        "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
        "\n",
        "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
        "\n",
        "print('\\nFalse Negatives(FN) = ', cm[1,0])\n",
        "\n",
        "print(\"------test (in long)--------\")\n",
        "precision, recall, fscore, support = precision_recall_fscore_support(y_test, pred, average='macro')\n",
        "print(\"Precision =\", precision)\n",
        "print(\"recall =\", recall)\n",
        "print(\"fscore =\", fscore)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cfdi28gv5siE",
        "outputId": "5c042624-ed54-4b07-e07a-71ee923a61a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------with stemmer-----\n",
            "-------Multinomial Naive Bayes-----\n",
            "------train--------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98       315\n",
            "           1       0.97      0.99      0.98       315\n",
            "\n",
            "    accuracy                           0.98       630\n",
            "   macro avg       0.98      0.98      0.98       630\n",
            "weighted avg       0.98      0.98      0.98       630\n",
            "\n",
            "------test--------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.66      0.68       135\n",
            "           1       0.68      0.73      0.70       135\n",
            "\n",
            "    accuracy                           0.69       270\n",
            "   macro avg       0.69      0.69      0.69       270\n",
            "weighted avg       0.69      0.69      0.69       270\n",
            "\n",
            "Confusion matrix\n",
            "\n",
            " [[89 46]\n",
            " [37 98]]\n",
            "\n",
            "True Positives(TP) =  89\n",
            "\n",
            "True Negatives(TN) =  98\n",
            "\n",
            "False Positives(FP) =  46\n",
            "\n",
            "False Negatives(FN) =  37\n",
            "------test (in long)--------\n",
            "Precision = 0.6934523809523809\n",
            "recall = 0.6925925925925926\n",
            "fscore = 0.6922506488691138\n",
            "----------------SVM----------\n",
            "------train--------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.94      0.95       315\n",
            "           1       0.94      0.97      0.96       315\n",
            "\n",
            "    accuracy                           0.96       630\n",
            "   macro avg       0.96      0.96      0.96       630\n",
            "weighted avg       0.96      0.96      0.96       630\n",
            "\n",
            "------test--------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.65      0.67       135\n",
            "           1       0.67      0.71      0.69       135\n",
            "\n",
            "    accuracy                           0.68       270\n",
            "   macro avg       0.68      0.68      0.68       270\n",
            "weighted avg       0.68      0.68      0.68       270\n",
            "\n",
            "Confusion matrix\n",
            "\n",
            " [[88 47]\n",
            " [39 96]]\n",
            "\n",
            "True Positives(TP) =  88\n",
            "\n",
            "True Negatives(TN) =  96\n",
            "\n",
            "False Positives(FP) =  47\n",
            "\n",
            "False Negatives(FN) =  39\n",
            "------test (in long)--------\n",
            "Precision = 0.6821210285777215\n",
            "recall = 0.6814814814814816\n",
            "fscore = 0.6812016036026141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Term frequency without stemmer\n"
      ],
      "metadata": {
        "id": "KD2nsuO26C4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# With stemmer\n",
        "#vectorizer = CountVectorizer(ngram_range=(1,1), preprocessor=preprocessing_sastrawi)\n",
        "# print(\"-------with stemmer-----\")\n",
        "\n",
        "# Without stemmers\n",
        "vectorizer = CountVectorizer(ngram_range=(1,1), preprocessor=preprocessing_without_stemmer)\n",
        "print(\"-------without stemmer-----\")\n",
        "\n",
        "# Preprocess and turn into vector\n",
        "X_train = vectorizer.fit_transform(train['Text Tweet'].values.tolist())\n",
        "\n",
        "# using multinomial naive bayes\n",
        "print(\"-------Multinomial Naive Bayes-----\")\n",
        "clf = MultinomialNB(alpha=0.01)\n",
        "X = X_train\n",
        "y = train['Sentiment'].values\n",
        "\n",
        "clf.fit(X, y)\n",
        "pred = clf.predict(X)\n",
        "print(\"------train--------\")\n",
        "print(classification_report(y, pred))\n",
        "\n",
        "X_test = vectorizer.transform(test['Text Tweet'].values.tolist())\n",
        "y_test = test['Sentiment'].values\n",
        "\n",
        "pred = clf.predict(X_test)\n",
        "print(\"------test--------\")\n",
        "print(classification_report(y_test, pred))\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, pred)\n",
        "\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "\n",
        "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
        "\n",
        "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
        "\n",
        "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
        "\n",
        "print('\\nFalse Negatives(FN) = ', cm[1,0])\n",
        "\n",
        "print(\"------test (in long)--------\")\n",
        "precision, recall, fscore, support = precision_recall_fscore_support(y_test, pred, average='macro')\n",
        "print(\"Precision =\", precision)\n",
        "print(\"recall =\", recall)\n",
        "print(\"fscore =\", fscore)\n",
        "\n",
        "\n",
        "#using svm\n",
        "print(\"----------------SVM----------\")\n",
        "svc = SVC()\n",
        "X = X_train\n",
        "y = train['Sentiment'].values\n",
        "\n",
        "svc.fit(X, y)\n",
        "pred = svc.predict(X)\n",
        "print(\"------train--------\")\n",
        "print(classification_report(y, pred))\n",
        "\n",
        "X_test = vectorizer.transform(test['Text Tweet'].values.tolist())\n",
        "y_test = test['Sentiment'].values\n",
        "\n",
        "pred = svc.predict(X_test)\n",
        "print(\"------test--------\")\n",
        "print(classification_report(y_test, pred))\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, pred)\n",
        "\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "\n",
        "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
        "\n",
        "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
        "\n",
        "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
        "\n",
        "print('\\nFalse Negatives(FN) = ', cm[1,0])\n",
        "\n",
        "print(\"------test (in long)--------\")\n",
        "precision, recall, fscore, support = precision_recall_fscore_support(y_test, pred, average='macro')\n",
        "print(\"Precision =\", precision)\n",
        "print(\"recall =\", recall)\n",
        "print(\"fscore =\", fscore)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UFu6zrz4rur",
        "outputId": "a2c2d0c2-f8a3-42fd-a7e8-efab729cc973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------without stemmer-----\n",
            "-------Multinomial Naive Bayes-----\n",
            "------train--------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       315\n",
            "           1       0.99      1.00      0.99       315\n",
            "\n",
            "    accuracy                           0.99       630\n",
            "   macro avg       0.99      0.99      0.99       630\n",
            "weighted avg       0.99      0.99      0.99       630\n",
            "\n",
            "------test--------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.64      0.66       135\n",
            "           1       0.66      0.70      0.68       135\n",
            "\n",
            "    accuracy                           0.67       270\n",
            "   macro avg       0.67      0.67      0.67       270\n",
            "weighted avg       0.67      0.67      0.67       270\n",
            "\n",
            "Confusion matrix\n",
            "\n",
            " [[87 48]\n",
            " [40 95]]\n",
            "\n",
            "True Positives(TP) =  87\n",
            "\n",
            "True Negatives(TN) =  95\n",
            "\n",
            "False Positives(FP) =  48\n",
            "\n",
            "False Negatives(FN) =  40\n",
            "------test (in long)--------\n",
            "Precision = 0.6746875172072022\n",
            "recall = 0.674074074074074\n",
            "fscore = 0.6737876874073261\n",
            "----------------SVM----------\n",
            "------train--------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.94      0.95       315\n",
            "           1       0.94      0.97      0.96       315\n",
            "\n",
            "    accuracy                           0.96       630\n",
            "   macro avg       0.96      0.96      0.96       630\n",
            "weighted avg       0.96      0.96      0.96       630\n",
            "\n",
            "------test--------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.61      0.65       135\n",
            "           1       0.66      0.75      0.70       135\n",
            "\n",
            "    accuracy                           0.68       270\n",
            "   macro avg       0.68      0.68      0.68       270\n",
            "weighted avg       0.68      0.68      0.68       270\n",
            "\n",
            "Confusion matrix\n",
            "\n",
            " [[ 82  53]\n",
            " [ 34 101]]\n",
            "\n",
            "True Positives(TP) =  82\n",
            "\n",
            "True Negatives(TN) =  101\n",
            "\n",
            "False Positives(FP) =  53\n",
            "\n",
            "False Negatives(FN) =  34\n",
            "------test (in long)--------\n",
            "Precision = 0.6813703537841469\n",
            "recall = 0.6777777777777778\n",
            "fscore = 0.6761741959497649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# using TF-IDF\n",
        "## multinomial naive bayes\n",
        "\n",
        "###with stemmer sastrawi\n",
        "\n",
        "Precision = 0.7044215626892791\\\n",
        "recall = 0.7037037037037037\\\n",
        "fscore = 0.7034433521884782\n",
        "\n",
        "###without stemmer\n",
        "\n",
        "Precision = 0.6966848095002474 \\\n",
        "recall = 0.6962962962962963\\\n",
        "fscore = 0.6961462450592886\n",
        "\n",
        "## SVM\n",
        "###with stemmer sastrawi\n",
        "\n",
        "Precision = 0.7371541501976284\\\n",
        "recall = 0.737037037037037\\\n",
        "fscore = 0.7370045684652426\n",
        "\n",
        "###without stemmer\n",
        "\n",
        "Precision = 0.7407935898139509\\\n",
        "recall = 0.7407407407407407\\\n",
        "fscore = 0.7407265144863915\n"
      ],
      "metadata": {
        "id": "ZDQ5gt8UpW9Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# using Count Vectorizer\n",
        "## using multinomial naive bayes\n",
        "### with stemmer sastrawi\n",
        "Precision = 0.6934523809523809 \\\n",
        "recall = 0.6925925925925926\\\n",
        "fscore = 0.6922506488691138\n",
        "### without stemmer\n",
        "Precision = 0.6746875172072022\\\n",
        "recall = 0.674074074074074\\\n",
        "fscore = 0.6737876874073261\n",
        "## using SVM\n",
        "### with stemmer sastrawi\n",
        "Precision = 0.6821210285777215\\\n",
        "recall = 0.6814814814814816\\\n",
        "fscore = 0.6812016036026141\n",
        "### without stemmer\n",
        "Precision = 0.6813703537841469\\\n",
        "recall = 0.6777777777777778\\\n",
        "fscore = 0.6761741959497649"
      ],
      "metadata": {
        "id": "gAFnF5Ta6TGD"
      }
    }
  ]
}